# -*- coding: utf-8 -*-
"""
ui_steps.py ‚Äì ULTIMATE –≤–µ—Ä—Å–∏—è v0.25 —Å –ü–û–õ–ù–´–ú–ò –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø–ú–ò:
‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
- accurate_mode —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ session_state
- –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–æ–∫ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- Dynamic CV splits –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫
- Stratified sampling –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
- Edge cases –æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

‚úÖ –°–†–ï–î–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
- –õ—É—á—à–∏–π feedback –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

‚úÖ –ù–ò–ó–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
- –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
- –õ—É—á—à–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º
"""

import streamlit as st
import pandas as pd
import numpy as np
import time
import math
import numbers
import io
import plotly.express as px
import plotly.graph_objects as pgo
from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc
from sklearn.inspection import permutation_importance
from scipy.optimize import differential_evolution
from sklearn.model_selection import train_test_split
from sklearn.base import clone
import os
import logging

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
import ml_core
from utils import (
    detect_csv_sep, detect_file_encoding, human_time_ms, enforce_min_duration, 
    download_button, get_session_id, smart_sample_large_file, get_file_size_mb,
    sanitize_column_names, remove_duplicate_columns, validate_data_types,
    check_and_remove_duplicates, get_file_hash, estimate_memory_usage, optimize_dtypes
)
from ui_config import MODEL_DESCRIPTIONS, get_model_tags, RANDOM_SEED, MAX_DATASET_SIZE, SAMPLE_SIZE_FOR_LARGE_DATASETS

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
from ml_core import LGBM_AVAILABLE, CATBOOST_AVAILABLE, XGB_AVAILABLE, OPTUNA_AVAILABLE

logger = logging.getLogger(__name__)

# =========================================================
# STEP 0: HOME
# =========================================================

def render_step0_home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞."""
    st.title("ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Sminex ML!")
    st.markdown("""
    **Sminex ML ‚Äì —ç—Ç–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.**  
    –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç:  
    * **üìÅ –ó–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ** –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV/XLSX (–¥–æ 200 –ú–ë).  
    * **üéØ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å** —Ç–∏–ø –∑–∞–¥–∞—á–∏ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è).  
    * **ü§ñ –û–±—É—á–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å** –¥–µ—Å—è—Ç–∫–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º.  
    * **üìä –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å** –¥–µ—Ç–∞–ª–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏.  
    * **üîÆ –î–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã** –Ω–∞ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —Ç–∏–ø–æ–≤.  
    * **‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä "–ß—Ç–æ, –µ—Å–ª–∏?"** –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    """)
    
    st.info("‚ú® **–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ v0.25:**\n"
            "- ‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–¥–æ 8x –±—ã—Å—Ç—Ä–µ–µ)\n"
            "- üéØ Stratified sampling –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n"
            "- üßπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ç—Ä–æ–∫\n"
            "- üíæ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏\n"
            "- üìä –ë–æ–ª—å—à–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è multiclass –∑–∞–¥–∞—á")
    
    st.subheader("üöÄ –ö–∞–∫ –Ω–∞—á–∞—Ç—å?")
    st.markdown("""
    1. –ù–∞–∂–º–∏—Ç–µ **"üìÅ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"** –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é.  
    2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ (CSV –∏–ª–∏ Excel).  
    3. –°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ wizard'–∞.
    4. –ü–æ–ª—É—á–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ–≥–Ω–æ–∑—ã!
    """)
    
    if st.button("üöÄ –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç", type="primary", use_container_width=True):
        st.session_state.wizard_step = 1
        st.rerun()

# =========================================================
# STEP 1: UPLOAD
# =========================================================

def render_step1_upload():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö."""
    st.header("üìÅ –®–∞–≥ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV –∏–ª–∏ Excel. –î–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã, –≥–¥–µ:  
    * **–°—Ç—Ä–æ–∫–∏** ‚Äì —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–ª–∏–µ–Ω—Ç—ã, —Ç–æ–≤–∞—Ä—ã, —Å–æ–±—ã—Ç–∏—è).  
    * **–°—Ç–æ–ª–±—Ü—ã** ‚Äì —ç—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–ø—Ä–∏–∑–Ω–∞–∫–∏) —ç—Ç–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è.
    
    ‚ö° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
    - –ú–∏–Ω–∏–º—É–º 100 —Å—Ç—Ä–æ–∫ –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - –ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ–∞–π–ª–æ–≤ —Å –±–æ–ª–µ–µ —á–µ–º 10,000 —Å—Ç–æ–ª–±—Ü–æ–≤
    - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤
    """)
    
    # –û–ø—Ü–∏–∏ –¥–ª—è CSV
    csv_separator = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è CSV —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)",
        options=["–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", ";", ",", "\t", "|"],
        index=0,
        help="–î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
    )
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
    up = st.file_uploader(
        "CSV/XLSX —Ñ–∞–π–ª", 
        type=["csv", "xls", "xlsx"], 
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 200 –ú–ë. –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω—ã."
    )

    data_loaded = False
    if up is not None:
        try:
            file_size_mb = get_file_size_mb(up)
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö
            if file_size_mb > 100:
                st.warning(f"‚ö†Ô∏è –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª ({file_size_mb:.1f} –ú–ë). "
                          f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
            else:
                st.info(f"üì¶ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.1f} –ú–ë")
            
            t0 = time.time()
            
            # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            file_hash = None
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
            if up.name.lower().endswith(".csv"):
                first_bytes = up.read(50_000)
                file_hash = get_file_hash(first_bytes)  # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: hash –¥–ª—è –∫—ç—à–∞
                
                encoding = detect_file_encoding(first_bytes, cache_key=file_hash)
                up.seek(0)
                
                if csv_separator == "–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ":
                    sep = detect_csv_sep(first_bytes, encoding)
                    st.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞: **{encoding}**, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: **'{sep}'**")
                else:
                    sep = csv_separator
                    st.info(f"‚úÖ –ö–æ–¥–∏—Ä–æ–≤–∫–∞: **{encoding}**, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: **'{sep}'**")
                
                # smart_sample_large_file —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
                df = smart_sample_large_file(
                    up, sep, 
                    max_rows=MAX_DATASET_SIZE,
                    sample_size=SAMPLE_SIZE_FOR_LARGE_DATASETS,
                    encoding=encoding,
                    target_col=None,  # –ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ target –µ—â–µ –Ω–µ –∏–∑–≤–µ—Å—Ç–µ–Ω
                    task_type=None
                )
            
            else:  # Excel
                df = pd.read_excel(up)
                st.info(f"‚úÖ Excel —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df = sanitize_column_names(df)
            df = remove_duplicate_columns(df)
            
            # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫
            df, n_duplicates = check_and_remove_duplicates(df, warn=True)
            if n_duplicates > 0:
                dup_pct = (n_duplicates / (len(df) + n_duplicates)) * 100
                st.warning(f"‚ö†Ô∏è –£–¥–∞–ª–µ–Ω–æ {n_duplicates} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫ ({dup_pct:.1f}%). "
                          f"–î—É–±–ª–∏–∫–∞—Ç—ã –º–æ–≥—É—Ç –∏—Å–∫–∞–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
            if df.empty:
                st.error("‚ùå –§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω!")
                return
            
            if df.shape[0] < 2:
                st.error("‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å—Ç—Ä–æ–∫ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2)")
                return
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –û—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
            memory_mb = estimate_memory_usage(df)
            if memory_mb > 500:
                st.warning(f"‚ö†Ô∏è –î–∞—Ç–∞—Å–µ—Ç –∑–∞–Ω–∏–º–∞–µ—Ç {memory_mb:.1f} –ú–ë –≤ –ø–∞–º—è—Ç–∏. "
                          f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è...")
                with st.spinner("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö..."):
                    df = optimize_dtypes(df, aggressive=False)
                    new_memory_mb = estimate_memory_usage(df)
                    saved_mb = memory_mb - new_memory_mb
                    if saved_mb > 0:
                        st.success(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: —ç–∫–æ–Ω–æ–º–∏—è {saved_mb:.1f} –ú–ë –ø–∞–º—è—Ç–∏")
            
            st.session_state.timer_info = {"load_ms": int((time.time() - t0) * 1000)}
            st.success(
                f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: **{df.shape[0]:,}** —Å—Ç—Ä–æ–∫ √ó **{df.shape[1]}** —Å—Ç–æ–ª–±—Ü–æ–≤ "
                f"({human_time_ms(st.session_state.timer_info['load_ms'])})"
            )
            
            # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–°—Ç—Ä–æ–∫", f"{df.shape[0]:,}")
            with col2:
                st.metric("–°—Ç–æ–ª–±—Ü–æ–≤", df.shape[1])
            with col3:
                num_cols = df.select_dtypes(include=[np.number]).shape[1]
                st.metric("–ß–∏—Å–ª–æ–≤—ã—Ö", num_cols)
            with col4:
                cat_cols = df.select_dtypes(include=['object', 'category']).shape[1]
                st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö", cat_cols)
            
            st.dataframe(df.head(10), use_container_width=True)
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
            if df.shape[0] > MAX_DATASET_SIZE:
                st.warning(
                    f"‚ö†Ô∏è –î–∞—Ç–∞—Å–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({df.shape[0]:,} —Å—Ç—Ä–æ–∫). "
                    f"–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –≤—ã–±–æ—Ä–∫–∞ –∏–∑ {SAMPLE_SIZE_FOR_LARGE_DATASETS:,} —Å—Ç—Ä–æ–∫."
                )
                df = df.sample(n=SAMPLE_SIZE_FOR_LARGE_DATASETS, random_state=RANDOM_SEED)
                st.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –≤—ã–±–æ—Ä–∫–∞: {df.shape[0]:,} √ó {df.shape[1]}")
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
            if df.shape[0] < 100:
                st.warning("‚ö†Ô∏è –ú–µ–Ω–µ–µ 100 —Å—Ç—Ä–æ–∫. –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∑–∫–∏–º. "
                          "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 —Å—Ç—Ä–æ–∫ –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
            
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–≤—ã—Ö
            keys_to_reset = [
                'target', 'task_type', 'train_df', 'X_train', 'X_test',
                'y_train', 'y_test', 'leaderboard', 'active_model_name', 'best_estimator',
                'fitted_pipe', 'prediction_data', 'primary_metric', 'selected_features',
                'available_features', 'calculator_base_data', 'dt_cols_hint',
                'timer_info', 'text_processing', 'use_log_transform', 'test_size',
                'accurate_mode'
            ]
            for key in keys_to_reset:
                if key in st.session_state:
                    st.session_state.pop(key, None)
            
            st.session_state.train_df = df
            data_loaded = True
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {df.shape}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ: {n_duplicates}")
        
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞:\n{str(e)[:200]}")
            logger.error(f"File upload error: {e}", exc_info=True)
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            with st.expander("üí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"):
                st.markdown("""
                - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω
                - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (—Å—Ç—Ä–æ–∫–∏ √ó —Å—Ç–æ–ª–±—Ü—ã)
                - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –≤ Excel/LibreOffice –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                - –ï—Å–ª–∏ —Ñ–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –µ–≥–æ —Ä–∞–∑–º–µ—Ä
                - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å UTF-8 –∏–ª–∏ CP1251)
                """)

    if st.button("‚û°Ô∏è –î–∞–ª–µ–µ", type="primary", disabled=not data_loaded, use_container_width=True):
        st.session_state.wizard_step = 2
        st.rerun()

# =========================================================
# STEP 2: SETUP (WITH TRAIN-TEST SPLIT)
# =========================================================

def render_step2_setup():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–¥–∞—á–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ train-test split."""
    st.header("üéØ –®–∞–≥ 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–¥–∞—á–∏: –¶–µ–ª—å –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏")

    df = st.session_state.get("train_df")
    if df is None:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –®–∞–≥ 1.")
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ –®–∞–≥ 1"):
            st.session_state.wizard_step = 1
            st.rerun()
        return

    cols = list(df.columns)

    st.markdown("#### üéØ 1. –í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (target)")
    st.markdown("–≠—Ç–æ —Ç–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å. –û–±—ã—á–Ω–æ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–æ–ª–±–µ—Ü –≤ —Ç–∞–±–ª–∏—Ü–µ.")
    
    current_target = st.session_state.get('target')
    target_index = cols.index(current_target) + 1 if current_target in cols else 0
    target = st.selectbox(
        "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", 
        options=["‚Äì –í—ã–±–µ—Ä–∏—Ç–µ ‚Äì"] + cols, 
        index=target_index,
        help="–°—Ç–æ–ª–±–µ—Ü —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å"
    )
    
    if target == "‚Äì –í—ã–±–µ—Ä–∏—Ç–µ ‚Äì":
        st.info("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, —á—Ç–æ–±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.")
        return
    
    st.session_state.target = target
    
    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ target
    with st.expander("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"):
        target_series = df[target]
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π", target_series.nunique())
        with col2:
            missing_pct = (target_series.isna().sum() / len(target_series)) * 100
            st.metric("–ü—Ä–æ–ø—É—Å–∫–æ–≤", f"{missing_pct:.1f}%")
        with col3:
            st.metric("–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö", str(target_series.dtype))
        
        if target_series.nunique() < 20:
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π:**")
            value_counts = target_series.value_counts().head(10)
            st.bar_chart(value_counts)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    try:
        task_type = ml_core.detect_problem_type(df[target], get_session_id())
        st.session_state.task_type = task_type
        st.session_state.primary_metric = ml_core.get_primary_metric(task_type)
        
        # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ë–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        task_emoji = {"binary": "üîµ", "multiclass": "üåà", "regression": "üìà"}
        st.success(
            f"{task_emoji.get(task_type, 'üéØ')} –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –∑–∞–¥–∞—á–∏: **{task_type}**. "
            f"–û—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞: **{st.session_state.primary_metric}**"
        )
        
        # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        if task_type == "binary":
            st.info("üí° **–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ (–¥–∞/–Ω–µ—Ç, 0/1, –∏ —Ç.–¥.)")
        elif task_type == "multiclass":
            st.info("üí° **–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤")
        else:
            st.info("üí° **–†–µ–≥—Ä–µ—Å—Å–∏—è:** –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —á–∏—Å–ª–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è")
            
    except ValueError as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:\n{str(e)}")
        return

    # –û–ø—Ü–∏—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞
    st.markdown("#### üéØ 1.1. –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    task_override = st.selectbox(
        "–ï—Å–ª–∏ —Ç–∏–ø –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:",
        options=["–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "binary", "multiclass", "regression"],
        index=0,
        help="–û–±—ã—á–Ω–æ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
    )
    if task_override != "–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ":
        st.session_state.task_type = task_override
        st.session_state.primary_metric = ml_core.get_primary_metric(task_override)
        st.info(f"‚úÖ –¢–∏–ø –∑–∞–¥–∞—á–∏ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: **{task_override}**")

    st.markdown("#### üìä 2. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –¥–∞–Ω–Ω—ã—Ö")
    st.markdown("–ò—Å–∫–ª—é—á–∏—Ç–µ –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏ —É–∫–∞–∂–∏—Ç–µ, –≥–¥–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –¥–∞—Ç—ã/–≤—Ä–µ–º—è.")

    available_features = [col for col in df.columns if col != target]
    st.session_state.available_features = available_features

    with st.form("features_and_dates_form"):
        selected_features = st.multiselect(
            "–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç–æ, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ):",
            options=available_features,
            default=st.session_state.get('selected_features', available_features[:20] if len(available_features) > 20 else available_features),
            help="–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –≤—Å–µ"
        )
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ
        if not selected_features:
            selected_features = available_features
        
        # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö date —Å—Ç–æ–ª–±—Ü–æ–≤
        potential_dt_cols = [
            c for c in selected_features
            if any(k in c.lower() for k in ["date", "–≤—Ä–µ–º—è", "time", "–¥–∞—Ç–∞", "timestamp"]) or 
            pd.api.types.is_datetime64_any_dtype(df[c])
        ]
        
        dt_cols_hint = st.multiselect(
            "–°—Ç–æ–ª–±—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –¥–∞—Ç—É/–≤—Ä–µ–º—è (–¥–ª—è –∞–≤—Ç–æ-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):",
            options=potential_dt_cols,
            default=st.session_state.get('dt_cols_hint', []),
            help="–ò–∑ —ç—Ç–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –±—É–¥—É—Ç –∏–∑–≤–ª–µ—á–µ–Ω—ã –≥–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –∏ —Ç.–¥."
        )

        # –û–ø—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        st.markdown("**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:**")
        
        text_processing = st.checkbox(
            "‚úÖ –í–∫–ª—é—á–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (TF-IDF)",
            value=st.session_state.get('text_processing', False),
            help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å –ø–æ–º–æ—â—å—é TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"
        )
        st.session_state.text_processing = text_processing

        use_log_transform = st.checkbox(
            "‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å log-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º",
            value=st.session_state.get('use_log_transform', False),
            help="–ü–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç log1p)"
        )
        st.session_state.use_log_transform = use_log_transform
        
        # Train-test split ratio
        test_size = st.slider(
            "üìä –ü—Ä–æ—Ü–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞",
            min_value=0.1, max_value=0.5, value=0.2, step=0.05,
            help="20% –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∑–Ω–∞—á–∞–µ—Ç 80% train, 20% test"
        )
        
        st.markdown("---")
        submitted = st.form_submit_button("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∏ —Å–æ–∑–¥–∞—Ç—å split", type="primary", use_container_width=True)
        
        if submitted:
            st.session_state.selected_features = selected_features
            st.session_state.dt_cols_hint = dt_cols_hint
            st.session_state.test_size = test_size
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞
            if len(selected_features) == 0:
                st.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫!")
                return
            
            if len(selected_features) > 1000:
                st.warning("‚ö†Ô∏è –í—ã–±—Ä–∞–Ω–æ –±–æ–ª–µ–µ 1000 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –¥–æ–ª–≥–æ–º—É –æ–±—É—á–µ–Ω–∏—é.")
            
            # –°–æ–∑–¥–∞–µ–º train-test split
            try:
                X = df[selected_features].copy()
                y = df[target].copy()
                
                # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                valid_idx = y.notna()
                X = X[valid_idx]
                y = y[valid_idx]
                
                if len(X) < 4:
                    st.error("‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è split (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 4 —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤)")
                    return
                
                # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –°–æ–∑–¥–∞–µ–º stratified split –µ—Å–ª–∏ —ç—Ç–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                try:
                    stratify_col = None
                    if st.session_state.task_type in ('binary', 'multiclass'):
                        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∫–ª–∞—Å—Å—ã –∏–º–µ—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤
                        class_counts = y.value_counts()
                        min_class_count = class_counts.min()
                        min_test_samples = int(len(y) * test_size)
                        
                        if min_class_count >= 2 and min_test_samples >= len(class_counts):
                            stratify_col = y
                            st.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è stratified split –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∫–ª–∞—Å—Å–æ–≤")
                        else:
                            st.warning(f"‚ö†Ô∏è Stratified split –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω (–º–∏–Ω. –∫–ª–∞—Å—Å: {min_class_count}). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è random split.")
                    
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=test_size, random_state=RANDOM_SEED,
                        stratify=stratify_col
                    )
                except Exception as e:
                    logger.warning(f"Stratified split failed: {e}, using regular split")
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=test_size, random_state=RANDOM_SEED
                    )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
                st.session_state.X_train = X_train.reset_index(drop=True)
                st.session_state.X_test = X_test.reset_index(drop=True)
                st.session_state.y_train = y_train.reset_index(drop=True)
                st.session_state.y_test = y_test.reset_index(drop=True)
                
                # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É split
                st.success(f"‚úÖ Train-Test Split —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("üìä Train —Ä–∞–∑–º–µ—Ä", f"{len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)")
                    if st.session_state.task_type in ('binary', 'multiclass'):
                        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (train):**")
                        train_dist = y_train.value_counts()
                        st.bar_chart(train_dist)
                
                with col2:
                    st.metric("üìä Test —Ä–∞–∑–º–µ—Ä", f"{len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)")
                    if st.session_state.task_type in ('binary', 'multiclass'):
                        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (test):**")
                        test_dist = y_test.value_counts()
                        st.bar_chart(test_dist)
                
                logger.info(f"Split created: train={len(X_train)}, test={len(X_test)}")
                
                time.sleep(1)
                st.session_state.wizard_step = 3
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ split: {str(e)}")
                logger.error(f"Split error: {e}", exc_info=True)

# =========================================================
# STEP 3: TRAINING
# =========================================================

def render_step3_training():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π."""
    st.header("ü§ñ –®–∞–≥ 3. –û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")

    if 'train_df' not in st.session_state or 'target' not in st.session_state:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≤–µ—Ä—à–∏—Ç–µ —à–∞–≥–∏ 1 –∏ 2.")
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ split —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if 'X_train' not in st.session_state or 'X_test' not in st.session_state:
        st.error("‚ùå Train-Test Split –Ω–µ –Ω–∞–π–¥–µ–Ω! –í–µ—Ä–Ω–∏—Ç–µ—Å—å –Ω–∞ —à–∞–≥ 2.")
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ —à–∞–≥ 2"):
            st.session_state.wizard_step = 2
            st.rerun()
        return

    X_train = st.session_state.X_train
    X_test = st.session_state.X_test
    y_train = st.session_state.y_train
    y_test = st.session_state.y_test
    
    df = st.session_state.train_df
    target_col = st.session_state.target
    task = st.session_state.task_type

    features = st.session_state.get('selected_features') or st.session_state.get('available_features', [])
    
    if not features:
        st.error("‚ùå –ù–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return
    
    # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
    st.info(f"üìä –û–±—É—á–µ–Ω–∏–µ –Ω–∞ **{len(X_train):,}** —Å—Ç—Ä–æ–∫–∞—Ö —Å **{len(features)}** –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏. "
            f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ **{len(X_test):,}** —Å—Ç—Ä–æ–∫–∞—Ö.")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ n_splits
    n_splits = ml_core.get_optimal_cv_splits(len(X_train))
    st.info(f"‚ÑπÔ∏è –î–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ **{n_splits} folds**")

    st.markdown("#### ‚ÑπÔ∏è –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Ä–µ–∂–∏–º—ã")
    st.success(
        "–í –æ–±—É—á–µ–Ω–∏–∏ —É—á–∞—Å—Ç–≤—É—é—Ç —Ç–æ–ª—å–∫–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: "
        f"sklearn (–≤—Å–µ–≥–¥–∞), "
        f"XGBoost {'‚úÖ' if ml_core.XGB_AVAILABLE else '‚ùå'}, "
        f"LightGBM {'‚úÖ' if ml_core.LGBM_AVAILABLE else '‚ùå'}, "
        f"CatBoost {'‚úÖ' if ml_core.CATBOOST_AVAILABLE else '‚ùå'}, "
        f"Optuna {'‚úÖ' if OPTUNA_AVAILABLE else '‚ùå'} –¥–ª—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
    )
    st.caption(
        "üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞: –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (>50k —Å—Ç—Ä–æ–∫) –Ω–∞—á–Ω–∏—Ç–µ —Å –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ–∂–∏–º–∞, "
        "—á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –º–∏–Ω—É—Ç—ã, –∞ –∑–∞—Ç–µ–º –≤–∫–ª—é—á–∞–π—Ç–µ —Ç–æ—á–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Ç–æ–ø-–º–æ–¥–µ–ª–µ–π."
    )

    # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ session_state
    st.markdown("### ‚öôÔ∏è –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º (5-10 –º–∏–Ω)**")
        st.caption("- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n"
                  "- –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏\n"
                  "- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
                  "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    with col2:
        st.markdown("**üéØ –¢–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (30-120 –º–∏–Ω)**")
        st.caption("- Optuna –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n"
                  "- –î–æ 50 trials –Ω–∞ –º–æ–¥–µ–ª—å\n"
                  "- Early stopping\n"
                  f"- {'‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω' if OPTUNA_AVAILABLE else '‚ùå –¢—Ä–µ–±—É–µ—Ç Optuna'}")
    
    mode = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º",
        ["‚ö° –ë—ã—Å—Ç—Ä–æ (5-10 –º–∏–Ω)", "üéØ –¢–æ—á–Ω–æ (30-120 –º–∏–Ω, Optuna)"],
        horizontal=True,
        index=1 if st.session_state.get('accurate_mode', False) else 0,
        help="–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. –¢–æ—á–Ω—ã–π - –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å Optuna."
    )
    accurate_mode = (mode == "üéØ –¢–æ—á–Ω–æ (30-120 –º–∏–Ω, Optuna)")
    st.session_state.accurate_mode = accurate_mode  # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state

    if accurate_mode and not OPTUNA_AVAILABLE:
        st.warning("‚ö†Ô∏è Optuna –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º")
        accurate_mode = False
        st.session_state.accurate_mode = False

    if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", type="primary", use_container_width=True):
        if accurate_mode:
            st.info("‚è≥ –ó–∞–ø—É—â–µ–Ω —Ä–µ–∂–∏–º —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å Optuna. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-120 –º–∏–Ω—É—Ç...\n"
                   "üí° **–°–æ–≤–µ—Ç:** Optuna –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π (early stopping)")

            if task == "regression":
                models_to_tune = ["Ridge", "Lasso", "RandomForestRegressor"]
                if XGB_AVAILABLE:
                    models_to_tune.append("XGBRegressor")
                if LGBM_AVAILABLE:
                    models_to_tune.append("LGBMRegressor")
                if CATBOOST_AVAILABLE:
                    models_to_tune.append("CatBoostRegressor")
            else:
                models_to_tune = ["LogisticRegression", "RandomForestClassifier"]
                if XGB_AVAILABLE:
                    models_to_tune.append("XGBClassifier")
                if LGBM_AVAILABLE:
                    models_to_tune.append("LGBMClassifier")
                if CATBOOST_AVAILABLE:
                    models_to_tune.append("CatBoostClassifier")

            results = []
            progress_bar = st.progress(0, text="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏...")
            status_text = st.empty()
            t0_all = time.time()

            cv = ml_core.get_cv(task, n_splits=n_splits, shuffle=True, seed=RANDOM_SEED)
            dt_cols_hint = st.session_state.get('dt_cols_hint')

            for i, name in enumerate(models_to_tune):
                status_text.info(
                    f"üîß –¢–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ {i+1}/{len(models_to_tune)}: **{name}** "
                    f"(Optuna, –¥–æ 50 trials —Å early stopping)"
                )
                
                model_start = time.time()
                best_model = ml_core.tune_with_optuna(
                    name, X_train, y_train, cv,
                    n_trials=50,
                    dt_cols_hint=dt_cols_hint
                )
                model_duration = time.time() - model_start
                
                if best_model is None:
                    st.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")
                    continue

                # CV evaluation
                preprocessor = ml_core.build_preprocessor(
                    X_train,
                    dt_cols_hint,
                    ml_core.is_linear_model(name),
                    True,
                    _sid=get_session_id(),
                    text_processing=st.session_state.get('text_processing', False),
                    model_name=name,
                    use_log_transform=st.session_state.get('use_log_transform', False)
                )
                
                scores, duration = ml_core.cv_evaluate(
                    preprocessor,
                    best_model, X_train, y_train, task,
                    n_splits=n_splits, shuffle=True, seed=RANDOM_SEED,
                    _sid=get_session_id(),
                    _cache_bust=i
                )
                
                row = {
                    "model": name, 
                    "cv_time": human_time_ms(duration),
                    "tune_time": human_time_ms(model_duration * 1000),
                    **scores
                }
                results.append(row)
                progress_bar.progress((i + 1) / len(models_to_tune), text=f"‚úÖ –ì–æ—Ç–æ–≤–æ: {name}")

            status_text.empty()
            progress_bar.empty()

        else:  # Fast mode
            models = ml_core.get_models(task, mode="fast")
            if not models:
                st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
                return

            dt_cols_hint = st.session_state.get('dt_cols_hint')
            text_processing = st.session_state.get('text_processing', False)
            use_log_transform = st.session_state.get('use_log_transform', False)

            preprocessors = {
                False: ml_core.build_preprocessor(
                    X_train, dt_cols_hint, use_scaler=False, handle_outliers=True,
                    _sid=get_session_id(),
                    text_processing=text_processing,
                    model_name=None,
                    use_log_transform=use_log_transform
                ),
                True: ml_core.build_preprocessor(
                    X_train, dt_cols_hint, use_scaler=True, handle_outliers=True,
                    _sid=get_session_id(),
                    text_processing=text_processing,
                    model_name=None,
                    use_log_transform=use_log_transform
                )
            }

            results = []
            progress_bar = st.progress(0, text="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è...")
            status_text = st.empty()
            t0_all = time.time()

            cv = ml_core.get_cv(task, n_splits=n_splits, shuffle=True, seed=RANDOM_SEED)

            for i, (name, model) in enumerate(models.items()):
                status_text.info(f"ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {i+1}/{len(models)}: **{name}**")
                
                needs_scaler = ml_core.is_linear_model(name)
                preprocessor = preprocessors[needs_scaler]

                scores, duration = ml_core.cv_evaluate(
                    preprocessor, model, X_train, y_train, task,
                    n_splits=n_splits, shuffle=True, seed=RANDOM_SEED,
                    _sid=get_session_id(),
                    _cache_bust=i
                )
                
                row = {"model": name, "cv_time": human_time_ms(duration), **scores}
                results.append(row)
                progress_bar.progress((i + 1) / len(models), text=f"‚úÖ –ì–æ—Ç–æ–≤–æ: {name}")

            status_text.empty()
            progress_bar.empty()

        enforce_min_duration(t0_all, min_seconds=2.0)
        
        # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –õ–∏–¥–µ—Ä–±–æ–∞—Ä–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π NaN
        leaderboard = pd.DataFrame(results)
        
        if leaderboard.empty:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.")
            return
        
        primary_metric = st.session_state.primary_metric
        sort_metric = ml_core.choose_sort_metric(leaderboard, task, primary_metric)
        
        if sort_metric and sort_metric in leaderboard.columns:
            ascending = ml_core.metric_ascending(sort_metric)
            leaderboard = leaderboard.sort_values(
                by=sort_metric,
                ascending=ascending,
                key=lambda s: s.fillna(float('inf') if ascending else float('-inf'))
            ).reset_index(drop=True)

        st.session_state.leaderboard = leaderboard
        best_model_name = ml_core.select_best_model(leaderboard, task, sort_metric)
        
        if not best_model_name:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ NaN). "
                    "–í–æ–∑–º–æ–∂–Ω–æ –¥–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª—ã –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã.")
            return
        
        st.session_state.active_model_name = best_model_name

        st.success(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {human_time_ms((time.time() - t0_all) * 1000)}! "
                  f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç—Ä–∏–∫–µ '{sort_metric}': **{best_model_name}**")
        st.rerun()

    # –ü–æ–∫–∞–∑ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞ –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if 'leaderboard' in st.session_state:
        st.subheader("üìä –õ–∏–¥–µ—Ä–±–æ–∞—Ä–¥ –º–æ–¥–µ–ª–µ–π")
        
        # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        leaderboard_display = st.session_state.leaderboard.copy()
        
        # –°—Ç–∏–ª—å –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        def highlight_best(row):
            if row['model'] == st.session_state.active_model_name:
                return ['background-color: #d4edda'] * len(row)
            return [''] * len(row)
        
        st.dataframe(
            leaderboard_display.style.apply(highlight_best, axis=1).format(precision=4),
            use_container_width=True
        )

        st.subheader("üéØ –í—ã–±–æ—Ä –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        st.markdown("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö.")
        
        model_names = st.session_state.leaderboard['model'].tolist()
        active_model_idx = model_names.index(st.session_state.active_model_name) if st.session_state.active_model_name in model_names else 0
        new_active_model = st.selectbox(
            "–ê–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å", 
            model_names, 
            index=active_model_idx,
            help="–≠—Ç–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–∞ –Ω–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"
        )
        st.session_state.active_model_name = new_active_model

        if st.button(f"‚úÖ –û–±—É—á–∏—Ç—å '{new_active_model}' –Ω–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–µ–π—Ç–∏ –∫ –∞–Ω–∞–ª–∏–∑—É", 
                    type="primary", use_container_width=True):
            with st.spinner(f"–û–±—É—á–µ–Ω–∏–µ '{new_active_model}' –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ..."):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
                X_full = st.session_state.train_df[st.session_state.get('selected_features') or st.session_state.available_features].copy()
                y_full = st.session_state.train_df[st.session_state.target].copy()
                
                # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
                valid_idx = y_full.notna()
                X_full = X_full[valid_idx].reset_index(drop=True)
                y_full = y_full[valid_idx].reset_index(drop=True)
                
                dt_cols_hint = st.session_state.get('dt_cols_hint')
                text_processing = st.session_state.get('text_processing', False)
                use_log_transform = st.session_state.get('use_log_transform', False)
                
                # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º accurate_mode –∏–∑ session_state
                accurate_mode = st.session_state.get('accurate_mode', False)

                cv = ml_core.get_cv(task, n_splits=n_splits, shuffle=True, seed=RANDOM_SEED)
                
                if accurate_mode and OPTUNA_AVAILABLE:
                    best_model = ml_core.tune_with_optuna(
                        new_active_model, X_full, y_full, cv,
                        n_trials=50,
                        dt_cols_hint=dt_cols_hint
                    )
                    if best_model is None:
                        # Fallback –Ω–∞ fast model
                        best_model = ml_core.get_models(task, mode="fast").get(new_active_model)
                else:
                    best_model = ml_core.get_models(task, mode="fast").get(new_active_model)
                
                if best_model is None:
                    st.error(f"‚ùå –ú–æ–¥–µ–ª—å {new_active_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    return
                
                preprocessor = ml_core.build_preprocessor(
                    X_full, dt_cols_hint, 
                    use_scaler=ml_core.is_linear_model(new_active_model),
                    handle_outliers=True,
                    _sid=get_session_id(),
                    text_processing=text_processing,
                    model_name=new_active_model,
                    use_log_transform=use_log_transform
                )

                st.session_state.fitted_pipe = ml_core.fit_best(
                    preprocessor, best_model, X_full, y_full, _sid=get_session_id()
                )

            st.success(f"‚úÖ –ú–æ–¥–µ–ª—å '{new_active_model}' –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(X_full):,} —Å—Ç—Ä–æ–∫–∞—Ö!")
            st.session_state.wizard_step = 4
            st.rerun()

# =========================================================
# STEP 4: ANALYSIS
# =========================================================

def render_step4_analysis():
    """–ê–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
    st.header(f"üìä –®–∞–≥ 4. –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏: {st.session_state.get('active_model_name', '')}")

    if 'fitted_pipe' not in st.session_state:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –®–∞–≥–µ 3.")
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ –®–∞–≥ 3"):
            st.session_state.wizard_step = 3
            st.rerun()
        return

    if 'X_test' not in st.session_state or 'y_test' not in st.session_state:
        st.error("‚ùå –î–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –í–µ—Ä–Ω–∏—Ç–µ—Å—å –Ω–∞ —à–∞–≥ 2.")
        return

    est = st.session_state.fitted_pipe
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test
    task = st.session_state.task_type

    try:
        y_pred = est.predict(X_test)
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}")
        logger.error(f"Prediction error: {e}", exc_info=True)
        return

    st.subheader("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ")
    st.markdown(f"–û—Ü–µ–Ω–∫–∞ –Ω–∞ **{len(X_test):,}** –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.")
    
    if task == 'regression':
        rmse = math.sqrt(ml_core.mean_squared_error(y_test, y_pred))
        mae = ml_core.mean_absolute_error(y_test, y_pred)
        r2 = ml_core.r2_score(y_test, y_pred)
        
        c1, c2, c3 = st.columns(3)
        c1.metric("RMSE", f"{rmse:,.2f}", help="Root Mean Squared Error - —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞")
        c2.metric("MAE", f"{mae:,.2f}", help="Mean Absolute Error - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
        c3.metric("R¬≤", f"{r2:.3f}", help="Coefficient of determination - –¥–æ–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
        
        # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ì—Ä–∞—Ñ–∏–∫ predicted vs actual
        st.subheader("üìâ Predicted vs Actual")
        fig = px.scatter(
            x=y_test, y=y_pred, 
            labels={"x": "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è", "y": "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"},
            title="Predicted vs Actual Values"
        )
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é y=x
        fig.add_trace(pgo.Scatter(
            x=[y_test.min(), y_test.max()],
            y=[y_test.min(), y_test.max()],
            mode='lines',
            name='–ò–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è',
            line=dict(color='red', dash='dash')
        ))
        st.plotly_chart(fig, use_container_width=True)
        
    else:  # Classification
        from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score
        
        acc = ml_core.accuracy_score(y_test, y_pred)
        f1 = ml_core.f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        if task == 'binary':
            precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
            recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
            
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Accuracy", f"{acc:.3f}", help="–î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
            c2.metric("F1-score", f"{f1:.3f}", help="–ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ precision –∏ recall")
            c3.metric("Precision", f"{precision:.3f}", help="–¢–æ—á–Ω–æ—Å—Ç—å - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å—Ä–µ–¥–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö")
            c4.metric("Recall", f"{recall:.3f}", help="–ü–æ–ª–Ω–æ—Ç–∞ - –¥–æ–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö")
        else:
            balanced_acc = balanced_accuracy_score(y_test, y_pred)
            
            c1, c2, c3 = st.columns(3)
            c1.metric("Accuracy", f"{acc:.3f}", help="–î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
            c2.metric("F1-weighted", f"{f1:.3f}", help="–í–∑–≤–µ—à–µ–Ω–Ω—ã–π F1-score –ø–æ –∫–ª–∞—Å—Å–∞–º")
            c3.metric("Balanced Acc", f"{balanced_acc:.3f}", help="–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è accuracy (—É—á–∏—Ç—ã–≤–∞–µ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤)")

        st.subheader("üìµ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
        labels = sorted(y_test.unique())
        cm = confusion_matrix(y_test, y_pred, labels=labels)
        fig = px.imshow(
            cm, text_auto=True,
            labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", y="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", color="–ö–æ–ª-–≤–æ"),
            x=[str(l) for l in labels], y=[str(l) for l in labels], 
            color_continuous_scale='Blues',
            title="Confusion Matrix"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
        if len(labels) > 2:
            errors_per_class = {}
            for i, label in enumerate(labels):
                total = cm[i].sum()
                correct = cm[i, i]
                errors = total - correct
                errors_per_class[str(label)] = errors
            
            st.markdown("**–û—à–∏–±–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:**")
            errors_df = pd.DataFrame(list(errors_per_class.items()), columns=['–ö–ª–∞—Å—Å', '–û—à–∏–±–æ–∫'])
            errors_df = errors_df.sort_values('–û—à–∏–±–æ–∫', ascending=False)
            st.bar_chart(errors_df.set_index('–ö–ª–∞—Å—Å'))

    st.subheader("‚≠ê –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Permutation Importance)")
    st.markdown("–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –≤–∞–∂–µ–Ω –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏. "
               "–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –≤–∞–∂–Ω–µ–µ –ø—Ä–∏–∑–Ω–∞–∫.")
    
    with st.spinner("–†–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)..."):
        try:
            # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            sample_size = min(5000, len(X_test))
            X_sample = X_test.sample(n=sample_size, random_state=RANDOM_SEED)
            y_sample = y_test.loc[X_sample.index]
            
            result = permutation_importance(
                est, X_sample, y_sample, 
                n_repeats=10,  # ‚úÖ –£–í–ï–õ–ò–ß–ï–ù–û: –±–æ–ª—å—à–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                random_state=RANDOM_SEED, 
                n_jobs=ml_core.N_JOBS
            )
            
            importances = pd.DataFrame({
                'feature': X_sample.columns,
                'importance_mean': result.importances_mean,
                'importance_std': result.importances_std
            }).sort_values('importance_mean', ascending=True).tail(20)
            
            fig = px.bar(
                importances, 
                x='importance_mean', 
                y='feature', 
                orientation='h', 
                title="–¢–æ–ø-20 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
                error_x='importance_std',
                labels={'importance_mean': '–í–∞–∂–Ω–æ—Å—Ç—å (—Å—Ä–µ–¥–Ω–µ–µ)', 'feature': '–ü—Ä–∏–∑–Ω–∞–∫'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–µ–∫—Å—Ç–æ–º
            st.markdown("**–¢–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**")
            for i, row in importances.tail(5).iterrows():
                st.caption(f"**{row['feature']}**: {row['importance_mean']:.4f} ¬± {row['importance_std']:.4f}")
            
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å: {e}")
            logger.error(f"Feature importance error: {e}", exc_info=True)

    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –æ–±—É—á–µ–Ω–∏—é", use_container_width=True):
            st.session_state.wizard_step = 3
            st.rerun()
    with col2:
        if st.button("‚û°Ô∏è –î–∞–ª–µ–µ –∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—é", type="primary", use_container_width=True):
            st.session_state.wizard_step = 5
            st.rerun()

# =========================================================
# STEP 5: PREDICT
# =========================================================

def render_step5_predict():
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    st.header("üîÆ –®–∞–≥ 5. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    
    st.markdown("""
    –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–æ–≤—ã–π —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤. 
    –§–∞–π–ª –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å **—Ç–µ –∂–µ —Å—Ç–æ–ª–±—Ü—ã** (–ø—Ä–∏–∑–Ω–∞–∫–∏), —á—Ç–æ –∏ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ.
    
    ‚ö° **–í–∞–∂–Ω–æ:**
    - –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
    - –ù–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å
    - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    """)

    if 'fitted_pipe' not in st.session_state:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –®–∞–≥–µ 3.")
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ –®–∞–≥ 3"):
            st.session_state.wizard_step = 3
            st.rerun()
        return

    up = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è", 
        type=["csv", "xls", "xlsx"],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ –∂–µ —Å—Ç–æ–ª–±—Ü—ã, —á—Ç–æ –∏ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ"
    )
    
    if up:
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
            if up.name.lower().endswith('.csv'):
                first_bytes = up.read(50_000)
                file_hash = get_file_hash(first_bytes)
                encoding = detect_file_encoding(first_bytes, cache_key=file_hash)
                up.seek(0)
                
                sep = detect_csv_sep(first_bytes, encoding)
                up.seek(0)
                
                st.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞: **{encoding}**, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: **'{sep}'**")
                
                df_new = smart_sample_large_file(up, sep, encoding=encoding)
            else:
                df_new = pd.read_excel(up)
                st.info(f"‚úÖ Excel —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω")

            # –û—á–∏—Å—Ç–∫–∞
            df_new = sanitize_column_names(df_new)
            
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: **{df_new.shape[0]:,}** —Å—Ç—Ä–æ–∫ √ó **{df_new.shape[1]}** —Å—Ç–æ–ª–±—Ü–æ–≤")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–≤—å—é
            with st.expander("üëÅÔ∏è –ü—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df_new.head(10))
            
            est = st.session_state.fitted_pipe
            original_features = list(st.session_state.X_train.columns)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
            missing_cols = set(original_features) - set(df_new.columns)
            if missing_cols:
                st.error(f"‚ùå –í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {list(missing_cols)}")
                st.info("üí° **–ü–æ–¥—Å–∫–∞–∑–∫–∞:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã. "
                       "–ù–∞–∑–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Ç–æ—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å.")
                return

            df_to_predict = df_new[original_features].copy()
            
            # ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            is_valid, messages = validate_data_types(st.session_state.X_train, df_to_predict)
            
            if messages:
                with st.expander("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö"):
                    for msg in messages:
                        if msg.startswith("‚ùå"):
                            st.error(msg)
                        else:
                            st.warning(msg)
            
            if not is_valid:
                st.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
                return
            
            # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
            with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞..."):
                try:
                    predictions = est.predict(df_to_predict)
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}")
                    logger.error(f"Prediction error: {e}", exc_info=True)
                    return

            result_df = df_new.copy()
            result_df[f"prediction_{st.session_state.target}"] = predictions
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            if st.session_state.task_type in ('binary', 'multiclass') and hasattr(est, 'predict_proba'):
                try:
                    probas = est.predict_proba(df_to_predict)
                    classes = est.classes_
                    for i, cls in enumerate(classes):
                        result_df[f"proba_{cls}"] = probas[:, i]
                except Exception:
                    pass

            st.session_state.prediction_data = result_df
            st.success("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤!")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
            st.dataframe(result_df.head(20), use_container_width=True)
            
            # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            with st.expander("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"):
                pred_col = f"prediction_{st.session_state.target}"
                
                if st.session_state.task_type == 'regression':
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("–°—Ä–µ–¥–Ω–µ–µ", f"{result_df[pred_col].mean():.2f}")
                    with col2:
                        st.metric("–ú–µ–¥–∏–∞–Ω–∞", f"{result_df[pred_col].median():.2f}")
                    with col3:
                        st.metric("–ú–∏–Ω", f"{result_df[pred_col].min():.2f}")
                    with col4:
                        st.metric("–ú–∞–∫—Å", f"{result_df[pred_col].max():.2f}")
                    
                    st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:**")
                    fig = px.histogram(result_df, x=pred_col, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:**")
                    class_dist = result_df[pred_col].value_counts()
                    st.bar_chart(class_dist)

            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.subheader("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            col1, col2 = st.columns(2)
            
            with col1:
                csv_bytes = result_df.to_csv(index=False).encode('utf-8')
                download_button(csv_bytes, "predictions.csv", "üì• –°–∫–∞—á–∞—Ç—å CSV", "text/csv")
            
            with col2:
                try:
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        result_df.to_excel(writer, index=False, sheet_name='Predictions')
                    xlsx_bytes = output.getvalue()
                    download_button(xlsx_bytes, "predictions.xlsx", "üì• –°–∫–∞—á–∞—Ç—å XLSX", 
                                  "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                except Exception as e:
                    st.caption(f"XLSX –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)[:200]}")
            logger.error(f"Predict file error: {e}", exc_info=True)
            
            with st.expander("üí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"):
                st.markdown("""
                - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Ñ–∞–π–ª –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                - –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö
                - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                """)

    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –∞–Ω–∞–ª–∏–∑—É", use_container_width=True):
            st.session_state.wizard_step = 4
            st.rerun()
    with col2:
        if st.button("‚û°Ô∏è –î–∞–ª–µ–µ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", type="primary", use_container_width=True):
            st.session_state.wizard_step = 6
            st.rerun()

# =========================================================
# STEP 6: CALCULATOR (What-If)
# =========================================================

def render_step6_calculator():
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    st.header("‚öôÔ∏è –®–∞–≥ 6. –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ '–ß—Ç–æ, –µ—Å–ª–∏?'")
    
    st.markdown("""
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ—Ç –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.
    
    **–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
    1. –í—ã–±–µ—Ä–∏—Ç–µ –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    2. –£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    3. –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è
    4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
    5. –ü–æ–ª—É—á–∏—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    
    üí° **–°–æ–≤–µ—Ç:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º differential evolution –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –æ–ø—Ç–∏–º—É–º–∞.
    """)

    if 'fitted_pipe' not in st.session_state:
        st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –®–∞–≥–µ 3.")
        if st.button("‚¨ÖÔ∏è –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ –®–∞–≥ 3"):
            st.session_state.wizard_step = 3
            st.rerun()
        return

    est = st.session_state.fitted_pipe
    X_train = st.session_state.X_train
    task = st.session_state.task_type

    st.subheader("1Ô∏è‚É£ –í—ã–±–µ—Ä–∏—Ç–µ –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    st.markdown("–≠—Ç–æ –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø–∏—á–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.")
    
    idx = st.number_input(
        "–ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö",
        min_value=0, max_value=len(X_train)-1, value=0,
        help=f"–î–æ—Å—Ç—É–ø–Ω–æ —Å—Ç—Ä–æ–∫: 0-{len(X_train)-1}"
    )
    base_row = X_train.iloc[[idx]].copy()
    
    with st.expander("üëÅÔ∏è –ü–æ–∫–∞–∑–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É"):
        st.dataframe(base_row.T, use_container_width=True)
        
        # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        try:
            current_pred = est.predict(base_row)[0]
            st.info(f"üìä –¢–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏: **{current_pred:.4f}**")
        except Exception:
            pass

    st.subheader("2Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    
    all_features = base_row.columns.tolist()
    num_features = [f for f in all_features if pd.api.types.is_numeric_dtype(X_train[f])]
    cat_features = [f for f in all_features if not pd.api.types.is_numeric_dtype(X_train[f])]

    st.markdown("**–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**")
    st.caption("–£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º—É–º–∞")
    
    bounds = {}
    for f in num_features:
        col_data = X_train[f].dropna()
        if len(col_data) == 0:
            continue
        min_val, max_val = float(col_data.min()), float(col_data.max())
        if min_val == max_val:
            max_val = min_val + 1  # Avoid slider error
        
        # ‚úÖ –£–õ–£–ß–®–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        current_val = float(base_row[f].iloc[0])
        bounds[f] = st.slider(
            f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è '{f}' (—Ç–µ–∫—É—â–µ–µ: {current_val:.2f})", 
            min_val, max_val, (min_val, max_val),
            help=f"–ú–∏–Ω–∏–º—É–º: {min_val:.2f}, –ú–∞–∫—Å–∏–º—É–º: {max_val:.2f}"
        )

    st.markdown("**–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**")
    st.caption("–û—Ç–º–µ—Ç—å—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å")
    
    cat_choices = {}
    for f in cat_features:
        options = sorted([str(x) for x in X_train[f].dropna().unique()])
        if len(options) == 0:
            continue
        if st.checkbox(f"–†–∞–∑—Ä–µ—à–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ '{f}'", key=f"check_{f}"):
            cat_choices[f] = options

    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –µ—Å—Ç—å —á—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
    if not bounds and not cat_choices:
        st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—á–∏—Å–ª–æ–≤–æ–π –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π)")
        return

    st.subheader("3Ô∏è‚É£ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    
    col1, col2 = st.columns(2)
    with col1:
        if task == 'regression':
            objective = st.radio(
                "–¶–µ–ª—å", 
                ["–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å", "–ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"], 
                horizontal=True,
                help="–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º"
            )
        else:
            objective = "–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
            st.info("–¶–µ–ª—å: –ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    
    with col2:
        popsize = st.slider(
            "–†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏", 
            5, 50, 15,
            help="–ë–æ–ª—å—à–µ = –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ"
        )
        maxiter = st.slider(
            "–ú–∞–∫—Å. –∏—Ç–µ—Ä–∞—Ü–∏–∏", 
            10, 200, 50,
            help="–ë–æ–ª—å—à–µ = –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ"
        )

    if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é", type="primary", use_container_width=True):
        with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-5 –º–∏–Ω—É—Ç)..."):
            optimizable_num = list(bounds.keys())
            optimizable_cat = list(cat_choices.keys())

            optimizer_bounds = [bounds[f] for f in optimizable_num]
            for f in optimizable_cat:
                optimizer_bounds.append((0, len(cat_choices[f]) - 0.001))

            def objective_function(x):
                row_to_predict = base_row.copy()
                for i, f in enumerate(optimizable_num):
                    row_to_predict[f] = x[i]
                offset = len(optimizable_num)
                for i, f in enumerate(optimizable_cat):
                    choice_idx = int(x[offset + i])
                    row_to_predict[f] = cat_choices[f][choice_idx]
                
                try:
                    if task == 'regression':
                        score = est.predict(row_to_predict)[0]
                    else:
                        if hasattr(est, "predict_proba"):
                            score = est.predict_proba(row_to_predict).max()
                        else:
                            score = float(est.predict(row_to_predict)[0])
                except Exception:
                    return float('inf') if objective == "–ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å" else float('-inf')
                
                return -score if objective == "–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å" else score

            if not optimizer_bounds:
                st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            else:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ‚úÖ –£–õ–£–ß–®–ï–ù–û: Callback –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                iteration = [0]
                def callback(xk, convergence):
                    iteration[0] += 1
                    progress = min(100, int((iteration[0] / maxiter) * 100))
                    progress_bar.progress(progress)
                    status_text.text(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {iteration[0]}/{maxiter}")
                
                result = differential_evolution(
                    objective_function,
                    bounds=optimizer_bounds,
                    popsize=popsize,
                    maxiter=maxiter,
                    seed=RANDOM_SEED,
                    callback=callback,
                    workers=1,
                    updating='deferred'
                )
                
                progress_bar.empty()
                status_text.empty()

                st.success("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
                try:
                    base_pred = est.predict(base_row)[0]
                except Exception:
                    base_pred = 0
                opt_pred = -result.fun if objective == "–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å" else result.fun
                
                col1, col2, col3 = st.columns(3)
                col1.metric("–ë–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", f"{base_pred:.4f}")
                col2.metric("–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", f"{opt_pred:.4f}")
                improvement = opt_pred - base_pred
                col3.metric(
                    "–£–ª—É—á—à–µ–Ω–∏–µ", 
                    f"{improvement:+.4f}",
                    delta=f"{(improvement/abs(base_pred)*100 if base_pred != 0 else 0):.1f}%"
                )

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                optimal_row = base_row.copy()
                x_opt = result.x
                for i, f in enumerate(optimizable_num):
                    optimal_row[f] = x_opt[i]
                offset = len(optimizable_num)
                for i, f in enumerate(optimizable_cat):
                    choice_idx = int(x_opt[offset + i])
                    optimal_row[f] = cat_choices[f][choice_idx]

                st.subheader("üìÑ –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
                comparison_df = pd.concat([base_row, optimal_row])
                comparison_df.index = ["–ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞", "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞"]
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–∏–≤—à–∏–µ—Å—è —Å—Ç–æ–ª–±—Ü—ã
                changed_cols = [col for col in all_features 
                               if str(comparison_df[col].iloc[0]) != str(comparison_df[col].iloc[1])]
                
                if changed_cols:
                    st.dataframe(
                        comparison_df[changed_cols].T.style.format(precision=3),
                        use_container_width=True
                    )
                    
                    # ‚úÖ –î–û–ë–ê–í–õ–ï–ù–û: –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    st.markdown("**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**")
                    for col in changed_cols:
                        old_val = comparison_df[col].iloc[0]
                        new_val = comparison_df[col].iloc[1]
                        if pd.api.types.is_numeric_dtype(type(old_val)):
                            if new_val > old_val:
                                st.caption(f"üìà –£–≤–µ–ª–∏—á–∏—Ç—å **{col}** —Å {old_val:.2f} –¥–æ {new_val:.2f}")
                            else:
                                st.caption(f"üìâ –£–º–µ–Ω—å—à–∏—Ç—å **{col}** —Å {old_val:.2f} –¥–æ {new_val:.2f}")
                        else:
                            st.caption(f"üîÑ –ò–∑–º–µ–Ω–∏—Ç—å **{col}** —Å '{old_val}' –Ω–∞ '{new_val}'")
                else:
                    st.info("‚ÑπÔ∏è –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –±–∞–∑–æ–≤—ã–º–∏. "
                           "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–æ–∫—É.")

    st.markdown("---")
    if st.button("üè† –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ –≥–ª–∞–≤–Ω—É—é", use_container_width=True):
        # –û—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        for key in list(st.session_state.keys()):
            if key not in ["wizard_step", "session_id"]:
                del st.session_state[key]
        st.session_state.wizard_step = 0
        st.rerun()
